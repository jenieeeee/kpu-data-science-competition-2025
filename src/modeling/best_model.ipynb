{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109d5ca0",
   "metadata": {},
   "source": [
    "# 1. 프로젝트 설명: Best Model  \n",
    "제5회 KAIST-POSTECH-UNIST 데이터사이언스 경진대회  \n",
    "**타이어 불량 예측 및 시험 생산 의사결정 모델링**\n",
    "\n",
    "이 파일은 경진대회에서 가장 높은 점수를 기록한 모델 파이프라인을 정리한 것입니다.\n",
    "\n",
    "- 시뮬레이션/공정 데이터를 활용한 **불량(NG) 예측**\n",
    "- 비용 구조를 고려한 **Threshold 최적화 & Top-K 선택**\n",
    "- 최종적으로 `submission_best.csv` 제출 파일을 생성하는 것을 목표로 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30d34b",
   "metadata": {},
   "source": [
    "# 2. 라이브러리 & 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "# Colab 환경에서 Google Drive 마운트\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 대회에서 제공된 데이터 로드\n",
    "train = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
    "test = pd.read_csv(\"/content/drive/MyDrive/test.csv\")\n",
    "submission_base = pd.read_csv(\"/content/drive/MyDrive/sample_submission.csv\")\n",
    "\n",
    "# 원본 보존을 위해 작업용 복사본 사용\n",
    "train_fe = train.copy()\n",
    "test_fe = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcfa2cb",
   "metadata": {},
   "source": [
    "# 3. 기본 전처리 & p/x/y 컬럼 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ff229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 컬럼을 NG(1) / Good(0) 이진 타깃으로 변환\n",
    "train_fe[\"NG\"] = train_fe[\"Class\"].map({\"Good\": 0, \"NG\": 1}).astype(int)\n",
    "\n",
    "# 학습용 데이터에서는 Class 컬럼 제거\n",
    "train_fe = train_fe.drop(columns=[\"Class\"])\n",
    "\n",
    "# 테스트 데이터에서는 ID만 제거 (ID는 제출용에서 따로 사용)\n",
    "test_fe = test_fe.drop(columns=[\"ID\"])\n",
    "\n",
    "# p, x, y로 시작하는 시뮬레이션 컬럼들을 인덱스 순서대로 정렬\n",
    "p_cols = sorted(\n",
    "    [c for c in train.columns if c.startswith(\"p\") and c[1:].isdigit()],\n",
    "    key=lambda x: int(x[1:])\n",
    ")\n",
    "x_cols = sorted(\n",
    "    [c for c in train.columns if c.startswith(\"x\") and c[1:].isdigit()],\n",
    "    key=lambda x: int(x[1:])\n",
    ")\n",
    "y_cols = sorted(\n",
    "    [c for c in train.columns if c.startswith(\"y\") and c[1:].isdigit()],\n",
    "    key=lambda x: int(x[1:])\n",
    ")\n",
    "\n",
    "print(\"p feature 개수 :\", len(p_cols))\n",
    "print(\"x feature 개수 :\", len(x_cols))\n",
    "print(\"y feature 개수 :\", len(y_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15473e70",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y 시뮬레이션 결과를 요약 통계로 압축\n",
    "def add_xy_stats(df):\n",
    "    # x 요약\n",
    "    df[\"x_mean\"] = df[x_cols].mean(axis=1)\n",
    "    df[\"x_std\"]  = df[x_cols].std(axis=1)\n",
    "    df[\"x_max\"]  = df[x_cols].max(axis=1)\n",
    "    df[\"x_min\"]  = df[x_cols].min(axis=1)\n",
    "\n",
    "    # y 요약\n",
    "    df[\"y_mean\"] = df[y_cols].mean(axis=1)\n",
    "    df[\"y_std\"]  = df[y_cols].std(axis=1)\n",
    "    df[\"y_max\"]  = df[y_cols].max(axis=1)\n",
    "    df[\"y_min\"]  = df[y_cols].min(axis=1)\n",
    "\n",
    "    # x / y 비율 (스케일 차이를 고려해 클리핑)\n",
    "    ratio = df[\"x_mean\"] / (df[\"y_mean\"].abs() + 1e-6)\n",
    "    df[\"x_y_ratio\"] = ratio.clip(-10, 10)\n",
    "    return df\n",
    "\n",
    "\n",
    "# p 컬럼들을 일정 구간 단위(chunk)로 묶어 평균/표준편차를 계산\n",
    "def add_p_chunks(df, size=16):\n",
    "    # 예: size=16이면 p0~p15, p16~p31 ... 구간별 통계 추가\n",
    "    for i in range(0, len(p_cols), size):\n",
    "        cols = p_cols[i:i + size]\n",
    "        df[f\"pchunk_{i//size}_mean\"] = df[cols].mean(axis=1)\n",
    "        df[f\"pchunk_{i//size}_std\"]  = df[cols].std(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# p 컬럼의 인접한 값들 간 차이를 요약\n",
    "def add_p_diff(df):\n",
    "    # 행 기준으로 오른쪽 컬럼과의 차이를 계산\n",
    "    diff = df[p_cols].diff(axis=1).iloc[:, 1:]\n",
    "    df[\"p_diff_mean\"] = diff.mean(axis=1)\n",
    "    df[\"p_diff_std\"]  = diff.std(axis=1)\n",
    "    df[\"p_diff_max\"]  = diff.abs().max(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# p 컬럼에 PCA를 적용해 차원 축소 (시뮬레이션 곡면을 압축 표현)\n",
    "def run_p_pca(train_df, test_df, n=15):\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_df[p_cols])\n",
    "    test_scaled  = scaler.transform(test_df[p_cols])\n",
    "\n",
    "    pca = PCA(n_components=n, random_state=42)\n",
    "    train_p = pca.fit_transform(train_scaled)\n",
    "    test_p  = pca.transform(test_scaled)\n",
    "\n",
    "    for i in range(n):\n",
    "        train_df[f\"PCA_{i}\"] = train_p[:, i]\n",
    "        test_df[f\"PCA_{i}\"]  = test_p[:, i]\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# 설계 스펙을 범주형 타입으로 지정 (CatBoost에서 카테고리로 처리)\n",
    "def add_design_categories(df):\n",
    "    df[\"Width\"]  = df[\"Width\"].astype(\"category\")\n",
    "    df[\"Aspect\"] = df[\"Aspect\"].astype(\"category\")\n",
    "    df[\"Inch\"]   = df[\"Inch\"].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Target Encoding (카테고리별 평균 타깃값을 인코딩) + 약간의 노이즈\n",
    "def target_encode(train_df, test_df, col, target=\"NG\", n_splits=5, noise=0.01):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    te_col = f\"{col}_TE\"\n",
    "    train_df[te_col] = np.nan\n",
    "\n",
    "    # KFold로 out-of-fold 방식 target encoding\n",
    "    for tr_idx, val_idx in kf.split(train_df):\n",
    "        tr = train_df.iloc[tr_idx]\n",
    "        val = train_df.iloc[val_idx]\n",
    "        mapping = tr.groupby(col)[target].mean()\n",
    "        train_df.loc[val_idx, te_col] = val[col].map(mapping)\n",
    "\n",
    "    # 전체 train 기준 mapping으로 test 인코딩\n",
    "    full_map = train_df.groupby(col)[target].mean()\n",
    "    test_df[te_col] = test_df[col].map(full_map)\n",
    "\n",
    "    # 과적합 완화를 위해 작은 노이즈 추가\n",
    "    train_df[te_col] += np.random.normal(0, noise, len(train_df))\n",
    "    test_df[te_col]  += np.random.normal(0, noise, len(test_df))\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# Mass_Pilot(파일럿 여부)와 PCA 축을 곱한 상호작용 피처\n",
    "def add_masspilot_interaction(df, n):\n",
    "    for i in range(n):\n",
    "        df[f\"MP_PCA{i}\"] = df[\"Mass_Pilot\"].astype(int) * df[f\"PCA_{i}\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "# p 원본 컬럼을 기반으로 KMeans 클러스터 번호를 부여\n",
    "def add_cluster(train_raw, test_raw, train_fe, test_fe, n_clusters=5):\n",
    "    # p 차원 수가 많아서 PCA로 먼저 50차원 축소\n",
    "    pca = PCA(n_components=50, random_state=42)\n",
    "    train_p = pca.fit_transform(train_raw)\n",
    "    test_p  = pca.transform(test_raw)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    train_fe[\"cluster\"] = kmeans.fit_predict(train_p)\n",
    "    test_fe[\"cluster\"]  = kmeans.predict(test_p)\n",
    "\n",
    "    train_fe[\"cluster\"] = train_fe[\"cluster\"].astype(\"category\")\n",
    "    test_fe[\"cluster\"]  = test_fe[\"cluster\"].astype(\"category\")\n",
    "    return train_fe, test_fe\n",
    "\n",
    "\n",
    "# 학습에 사용할 feature 리스트 구성\n",
    "def get_feature_list(df, drop=[\"ID\", \"Plant\", \"Class\"], target=\"NG\"):\n",
    "    ignore = set(drop + [target])\n",
    "    return [c for c in df.columns if c not in ignore]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e1938",
   "metadata": {},
   "source": [
    "# 5. Feature Engineering 전체 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) p를 구간 단위로 요약\n",
    "train_fe = add_p_chunks(train_fe)\n",
    "test_fe  = add_p_chunks(test_fe)\n",
    "\n",
    "# 2) p의 인접 차이 요약\n",
    "train_fe = add_p_diff(train_fe)\n",
    "test_fe  = add_p_diff(test_fe)\n",
    "\n",
    "# 3) p에 PCA 적용 (15차원으로 축소)\n",
    "train_fe, test_fe = run_p_pca(train_fe, test_fe, n=15)\n",
    "\n",
    "# 4) 설계 스펙을 범주형으로 설정\n",
    "train_fe = add_design_categories(train_fe)\n",
    "test_fe  = add_design_categories(test_fe)\n",
    "\n",
    "# 5) Plant 문자열에서 번호만 추출 후 정수형으로 변환\n",
    "train_fe[\"Plant\"] = train_fe[\"Plant\"].astype(str).str.replace(\"Plant_\", \"\").astype(int)\n",
    "test_fe[\"Plant\"]  = test_fe[\"Plant\"].astype(str).str.replace(\"Plant_\", \"\").astype(int)\n",
    "\n",
    "# 6) Plant, Mass_Pilot에 대해 Target Encoding\n",
    "train_fe, test_fe = target_encode(train_fe, test_fe, col=\"Plant\")\n",
    "train_fe, test_fe = target_encode(train_fe, test_fe, col=\"Mass_Pilot\")\n",
    "\n",
    "# 7) Mass_Pilot × PCA 상호작용 피처\n",
    "train_fe = add_masspilot_interaction(train_fe, 15)\n",
    "test_fe  = add_masspilot_interaction(test_fe, 15)\n",
    "\n",
    "# 8) x, y 요약 통계 피처 추가\n",
    "train_fe = add_xy_stats(train_fe)\n",
    "test_fe  = add_xy_stats(test_fe)\n",
    "\n",
    "# 9) 원본 p 값 기반 KMeans 클러스터링\n",
    "train_fe, test_fe = add_cluster(train[p_cols], test[p_cols], train_fe, test_fe)\n",
    "\n",
    "# 10) object 타입은 category로 변환 (CatBoost에서 카테고리로 처리)\n",
    "obj_cols = train_fe.columns[train_fe.dtypes == \"object\"]\n",
    "obj_cols = [c for c in obj_cols if c not in [\"Class\"]]  # 혹시 남아있을 Class는 제외\n",
    "print(\"object cols -> category로 변환:\", obj_cols)\n",
    "\n",
    "for col in obj_cols:\n",
    "    train_fe[col] = train_fe[col].astype(\"category\")\n",
    "    if col in test_fe.columns:\n",
    "        test_fe[col] = test_fe[col].astype(\"category\")\n",
    "\n",
    "# 11) PCA로 대체했으므로 p 원본 컬럼은 드롭\n",
    "train_fe = train_fe.drop(columns=p_cols, errors=\"ignore\")\n",
    "test_fe  = test_fe.drop(columns=p_cols, errors=\"ignore\")\n",
    "\n",
    "# 12) 최종 학습에 사용할 feature 리스트\n",
    "final_features = get_feature_list(train_fe, drop=[\"Plant\"], target=\"NG\")\n",
    "print(\"최종 feature 수:\", len(final_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae9198",
   "metadata": {},
   "source": [
    "# 6. Profit 함수 & GroupKFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대회에서 정의된 수익 구조\n",
    "GAIN_GOOD = 100    # 좋은 타이어를 선택했을 때 +100\n",
    "GAIN_NG   = -2000  # 불량 타이어를 선택했을 때 -2000\n",
    "\n",
    "def profit_threshold(y, pred, th):\n",
    "    \"\"\"\n",
    "    예측 확률(pred) <= threshold 인 샘플을 선택한다고 가정했을 때의\n",
    "    총 수익을 계산한다.\n",
    "    y: 0(좋음), 1(NG)\n",
    "    pred: NG가 될 확률(값이 낮을수록 좋은 타이어)\n",
    "    \"\"\"\n",
    "    sel = pred <= th\n",
    "    if sel.sum() == 0:\n",
    "        return 0\n",
    "    bad = y[sel]\n",
    "    return (bad == 0).sum() * GAIN_GOOD + (bad == 1).sum() * GAIN_NG\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "N_SPLITS = 5\n",
    "\n",
    "# CatBoost에서 사용할 카테고리 feature index 추출\n",
    "cat_idx = [\n",
    "    i for i, c in enumerate(final_features)\n",
    "    if isinstance(train_fe[c].dtype, CategoricalDtype)\n",
    "]\n",
    "print(\"categorical features:\", [final_features[i] for i in cat_idx])\n",
    "\n",
    "# 공장(Plant)을 기준으로 GroupKFold 수행\n",
    "gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "X_all = train_fe[final_features]\n",
    "y_all = train_fe[\"NG\"].values\n",
    "groups = train_fe[\"Plant\"].values\n",
    "\n",
    "oof_pred = np.zeros(len(train_fe))\n",
    "fold_auc = []\n",
    "\n",
    "# Fold 0의 validation 결과를 이용해 threshold를 최적화\n",
    "best_thr_fold0 = None\n",
    "best_profit_fold0 = -1e18\n",
    "\n",
    "# 각 fold별 test 예측도 저장 (필요 시 앙상블 가능)\n",
    "test_pred_folds = np.zeros((len(test_fe), N_SPLITS))\n",
    "\n",
    "print(\"\\n===== GroupKFold CV 시작 =====\")\n",
    "for fold, (tr_idx, val_idx) in enumerate(gkf.split(X_all, y_all, groups)):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    X_tr, X_val = X_all.iloc[tr_idx], X_all.iloc[val_idx]\n",
    "    y_tr, y_val = y_all[tr_idx], y_all[val_idx]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=1500,\n",
    "        learning_rate=0.03,\n",
    "        depth=8,\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"AUC\",\n",
    "        random_state=SEED,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    model.fit(X_tr, y_tr, cat_features=cat_idx)\n",
    "\n",
    "    # validation에서 NG일 확률 예측\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    oof_pred[val_idx] = val_pred\n",
    "\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "    fold_auc.append(auc)\n",
    "    print(f\"Fold {fold} AUC: {auc:.4f}\")\n",
    "\n",
    "    # test 예측 저장\n",
    "    test_pred_folds[:, fold] = model.predict_proba(test_fe[final_features])[:, 1]\n",
    "\n",
    "    # Fold0에서만 threshold 후보들을 탐색해 best threshold 선택\n",
    "    if fold == 0:\n",
    "        ths = np.linspace(val_pred.min(), val_pred.max(), 501)\n",
    "        for th in ths:\n",
    "            p = profit_threshold(y_val, val_pred, th)\n",
    "            if p > best_profit_fold0:\n",
    "                best_profit_fold0 = p\n",
    "                best_thr_fold0 = th\n",
    "        print(f\"Fold0 기준 best threshold: {best_thr_fold0:.6f}\")\n",
    "        print(f\"Fold0 기준 best profit   : {best_profit_fold0:.0f}\")\n",
    "\n",
    "# 전체 OOF AUC 확인\n",
    "oof_auc = roc_auc_score(y_all, oof_pred)\n",
    "print(\"\\nFold별 AUC:\", [f\"{x:.4f}\" for x in fold_auc])\n",
    "print(\"OOF AUC   :\", oof_auc)\n",
    "print(\"최종 사용 threshold (Fold0 기반):\", best_thr_fold0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e32d5",
   "metadata": {},
   "source": [
    "# 7. 전체 Train으로 최종 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bf14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV에서 사용한 설정과 동일하게 전체 train으로 최종 모델 학습\n",
    "final_model = CatBoostClassifier(\n",
    "    iterations=1500,\n",
    "    learning_rate=0.03,\n",
    "    depth=8,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    random_state=SEED,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "final_model.fit(X_all, y_all, cat_features=cat_idx)\n",
    "\n",
    "# 최종 모델의 test 예측 (NG 확률)\n",
    "test_pred_final = final_model.predict_proba(test_fe[final_features])[:, 1]\n",
    "print(\"test_pred_final 범위:\", test_pred_final.min(), \" ~ \", test_pred_final.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
